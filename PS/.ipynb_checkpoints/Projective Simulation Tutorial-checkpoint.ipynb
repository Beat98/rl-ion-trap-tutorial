{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projective Simulation Tutorial\n",
    "\n",
    "__string__, `string` <br>\n",
    "$ mathematical symbols $ <br>\n",
    "\n",
    "1. first <br>\n",
    "2. second\n",
    "\n",
    "> indendet text\n",
    "\n",
    "</div><div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> Use blue boxes (alert-info) for tips and notes. \n",
    "If it’s a note, you don’t have to include the word “Note”.\n",
    "</div>\n",
    "\n",
    "__[link text](http://url)__\n",
    "\n",
    "```python\n",
    "def staySafe(Coronavirus)\n",
    "  if not home:\n",
    "    return home\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projective Simulation Tutorial\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a little bit of theory\n",
    "\n",
    "Am not afraid of this. There are just a few things you should understand basically bevore we can start with practice. So let's begin: <br>\n",
    "At first we should understand the model of Reinforcement Learning (RL), because Projective Simulation (PS) is a RL model. So take a look on this illustration:\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src=\"agent_env_interaction.png\" alt=\"xx\" style=\"width: 400px;\"/>\n",
    "\n",
    "You see the typical interaction between an agent and the environment. In our case the environment is the Ion Trap Environment (see Tutorial). The agent performs an action on the environment according to his observation and receives a possible reward. In the following we want to build a PS agent who is able to maximally entangle $N$ ions. So let's talk a bit about PS: <br>\n",
    "<br>\n",
    "Please do me a favor and read at least the abstract of this paper: __[link](https://arxiv.org/pdf/1104.3787.pdf)__ <br>\n",
    "The following sentence is important: \n",
    ">\"Projective simulation is based on a random walk through a network of clips,\n",
    "which are elementary patches of episodic memory\"\n",
    "\n",
    "The brain of the agent is the so-called episodic compositional memory (ECM), which contains some network of clips. The clips are some instances of memory. Here you see an example:\n",
    "<img src=\"general_clips_structure.png\" alt=\"xx\" style=\"width: 300px;\"/>\n",
    " \n",
    "If the agent makes an observation an so called percept clip (blue) is activated or generated and based on the structure of the clip network and the weights of the so called edges (blue arrows) the agent chooses an action clip (red) and executes an action. This is called random walk. <br>\n",
    "<br>\n",
    "\n",
    "Now that you understand the principal of PS let's start with the implementation! The mathematics will be introduced step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implemantation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need something which represents the clip network with the clips, the edges and the weights of the edges. Therefore an adjencency matrix is very usefull. I have an example for you:\n",
    "\n",
    "<img src=\"adj_matrix_example.png\" alt=\"xx\" style=\"width: 500px;\"/>\n",
    "<br>\n",
    "A field from the adjancency matrix represents the weight of a certain edge, which connects two clips. The edge points from one clip (row index) to another clip (column index).<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skeleton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to build a skeleton of our agent. <br>\n",
    "The agent should have the ability to choose an action for a given observation and it should learn from the recieved reward. Therefore it needs an ECM, the actions and the decision tree structure (adjancency matrix). <br>\n",
    "__TASK__: Write a new class skeleton `Agent()` with the `__init__()` function and two methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
